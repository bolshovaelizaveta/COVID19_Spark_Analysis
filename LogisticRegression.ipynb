{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03122039-a10d-4c80-90ff-7277f18260de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные для ML загружены из оптимизированного Parquet.\n",
      "root\n",
      " |-- patientid: string (nullable = true)\n",
      " |-- offset: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- finding: string (nullable = true)\n",
      " |-- RT_PCR_positive: string (nullable = true)\n",
      " |-- survival: string (nullable = true)\n",
      " |-- intubated: string (nullable = true)\n",
      " |-- intubation_present: string (nullable = true)\n",
      " |-- went_icu: string (nullable = true)\n",
      " |-- in_icu: string (nullable = true)\n",
      " |-- needed_supplemental_O2: string (nullable = true)\n",
      " |-- extubated: string (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- pO2_saturation: double (nullable = true)\n",
      " |-- leukocyte_count: double (nullable = true)\n",
      " |-- neutrophil_count: double (nullable = true)\n",
      " |-- lymphocyte_count: double (nullable = true)\n",
      " |-- view: string (nullable = true)\n",
      " |-- modality: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- folder: string (nullable = true)\n",
      " |-- filename: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- clinical_notes: string (nullable = true)\n",
      " |-- other_notes: string (nullable = true)\n",
      " |-- finding_unified: string (nullable = true)\n",
      " |-- date_parsed: date (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- is_covid: integer (nullable = true)\n",
      " |-- age_numeric: integer (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- hdfs_image_path: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "Заполнены пропуски в leukocyte_count средним 5.02\n",
      "Заполнены пропуски в neutrophil_count средним 5.31\n",
      "Заполнены пропуски в lymphocyte_count средним 4.64\n",
      "Начинаем разделение данных на обучающую и тестовую выборки...\n",
      "Обучающая выборка: 797 строк\n",
      "Тестовая выборка: 153 строк\n",
      "Начинаем обучение модели...\n",
      "Обучение модели завершено.\n",
      "Выполняем предсказания на тестовой выборке...\n",
      "+---------+--------+----------+------------------------------------------+\n",
      "|patientid|is_covid|prediction|probability                               |\n",
      "+---------+--------+----------+------------------------------------------+\n",
      "|112      |1       |0.0       |[0.7196708899989618,0.2803291100010382]   |\n",
      "|114      |1       |0.0       |[0.6008662980254003,0.39913370197459974]  |\n",
      "|115      |1       |0.0       |[0.6008662980254003,0.39913370197459974]  |\n",
      "|117      |1       |0.0       |[0.5561334789784026,0.4438665210215974]   |\n",
      "|12       |1       |1.0       |[0.16294338593720847,0.8370566140627915]  |\n",
      "|123      |1       |1.0       |[0.1152293800054515,0.8847706199945485]   |\n",
      "|129      |1       |1.0       |[0.10795132272644777,0.8920486772735522]  |\n",
      "|13       |1       |1.0       |[0.18540709049829673,0.8145929095017033]  |\n",
      "|134      |1       |1.0       |[0.0028766742190906567,0.9971233257809093]|\n",
      "|135      |1       |1.0       |[0.0014749520401481683,0.9985250479598519]|\n",
      "+---------+--------+----------+------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Оцениваем производительность модели...\n",
      "Area Under ROC (AUC) на тестовой выборке: 0.8835\n",
      "\n",
      "Количество признаков в модели: 24\n",
      "Коэффициенты модели логистической регрессии: [[ 0.15569132 -0.15569132  0.03247601 -0.03247601 -0.12611848  0.47729336\n",
      "   0.05383687 -1.53134928  0.49917676  2.12085453 -4.55020856 -0.85601475\n",
      "   0.85601475 -1.95999543  1.95999543  0.38295352 -0.15080019 -0.80309475\n",
      "   0.01835915 -0.07047965 -0.10493309  0.64478136  0.01838265 -0.02836752]]\n",
      "Пересечение (Intercept): 10.050194758470186\n",
      "SparkSession остановлена. Обучение и оценка ML-модели завершены.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, coalesce, lit \n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Инициализация SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"COVID19_ML_Model\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .config(\"spark.sql.parquet.datetimeRebaseModeInWrite\", \"LEGACY\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "optimized_parquet_path = \"hdfs:///covid_dataset/metadata_optimized/\"\n",
    "\n",
    "# Путь в HDFS, где хранятся очищенные и оптимизированные метаданные в формате Parquet\n",
    "df_ml = spark.read.parquet(optimized_parquet_path)\n",
    "\n",
    "print(\"Данные для ML загружены из оптимизированного Parquet.\")\n",
    "df_ml.printSchema()\n",
    "\n",
    "# Целевая переменная: is_covid (0 или 1)\n",
    "# Признаки: sex, age_group, view, modality, RT_PCR_positive, survival, temperature, pO2_saturation, leukocyte_count, neutrophil_count, lymphocyte_count\n",
    "\n",
    "# Список категориальных признаков, которые нужно индексировать и One-Hot-кодировать\n",
    "categorical_features = [\n",
    "    \"sex\",\n",
    "    \"age_group\",\n",
    "    \"view\",\n",
    "    \"modality\",\n",
    "    \"RT_PCR_positive\",\n",
    "    \"survival\"\n",
    "]\n",
    "\n",
    "# Список числовых признаков\n",
    "numeric_features = [\n",
    "    \"age_numeric\",\n",
    "    \"temperature\",\n",
    "    \"pO2_saturation\",\n",
    "    \"leukocyte_count\",\n",
    "    \"neutrophil_count\",\n",
    "    \"lymphocyte_count\"\n",
    "]\n",
    "\n",
    "# Валидация и заполнение пропусков в числовых признаках\n",
    "from pyspark.sql.functions import mean as _mean\n",
    "for nf in numeric_features:\n",
    "    if nf in df_ml.columns:\n",
    "        if df_ml.filter(col(nf).isNull()).count() > 0:\n",
    "            # Используем average для заполнения\n",
    "            avg_val = df_ml.select(_mean(col(nf))).collect()[0][0]\n",
    "            if avg_val is not None:\n",
    "                df_ml = df_ml.withColumn(nf, col(nf).cast(\"double\"))\n",
    "                df_ml = df_ml.na.fill(avg_val, subset=[nf]) \n",
    "                print(f\"Заполнены пропуски в {nf} средним {avg_val:.2f}\")\n",
    "            else:\n",
    "                print(f\"Предупреждение: Колонка {nf} содержит только NULL значения, невозможно заполнить средним.\")\n",
    "                df_ml = df_ml.withColumn(nf, lit(0.0).cast(\"double\")) # Заполняем 0.0 если все NULL\n",
    "    else:\n",
    "        print(f\"Предупреждение: Числовая колонка '{nf}' не найдена в DataFrame. Пропускаем.\")\n",
    "        numeric_features.remove(nf) # Удаляем несуществующие колонки из списка\n",
    "\n",
    "# Создаем стадии Pipeline для StringIndexer и OneHotEncoderEstimator\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=feature, outputCol=feature + \"_indexed\", handleInvalid=\"keep\")\n",
    "    for feature in categorical_features if feature in df_ml.columns\n",
    "]\n",
    "\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCol=feature + \"_indexed\", outputCol=feature + \"_encoded\")\n",
    "    for feature in categorical_features if feature in df_ml.columns # Аналогично\n",
    "]\n",
    "\n",
    "assembler_inputs = [f.getOutputCol() for f in encoders] + numeric_features\n",
    "\n",
    "if not assembler_inputs:\n",
    "    raise ValueError(\"Не найдено действительных признаков для VectorAssembler после всех преобразований. Проверьте списки признаков и схему DataFrame.\")\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "# Модель классификации: Логистическая регрессия\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"is_covid\", maxIter=10)\n",
    "\n",
    "# Создание Pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [vector_assembler, lr])\n",
    "\n",
    "print(\"Начинаем разделение данных на обучающую и тестовую выборки...\")\n",
    "# Разделение данных на обучающую 80% и тестовую 20% \n",
    "(training_data, test_data) = df_ml.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Обучающая выборка: {training_data.count()} строк\")\n",
    "print(f\"Тестовая выборка: {test_data.count()} строк\")\n",
    "\n",
    "print(\"Начинаем обучение модели...\")\n",
    "# Обучение модели\n",
    "model = pipeline.fit(training_data)\n",
    "print(\"Обучение модели завершено.\")\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "print(\"Выполняем предсказания на тестовой выборке...\")\n",
    "predictions = model.transform(test_data)\n",
    "predictions.select(\"patientid\", \"is_covid\", \"prediction\", \"probability\").show(10, truncate=False)\n",
    "\n",
    "# Оценка модели\n",
    "print(\"Оцениваем производительность модели...\")\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"is_covid\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"Area Under ROC (AUC) на тестовой выборке: {auc:.4f}\")\n",
    "\n",
    "try:\n",
    "    lr_model = model.stages[-1]\n",
    "    print(f\"\\nКоличество признаков в модели: {lr_model.numFeatures}\")\n",
    "    if lr_model.numFeatures > 0:\n",
    "        print(f\"Коэффициенты модели логистической регрессии: {lr_model.coefficientMatrix.toArray()}\")\n",
    "    print(f\"Пересечение (Intercept): {lr_model.intercept}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nНе удалось получить коэффициенты логистической регрессии: {e}\")\n",
    "\n",
    "spark.stop()\n",
    "print(\"SparkSession остановлена. Обучение и оценка ML-модели завершены.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
